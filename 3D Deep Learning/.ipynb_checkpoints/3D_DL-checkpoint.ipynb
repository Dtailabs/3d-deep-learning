{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: open3d in /root/anaconda/envs/ai/lib/python3.8/site-packages (0.12.0)\n",
      "Requirement already satisfied: pandas in /root/anaconda/envs/ai/lib/python3.8/site-packages (from open3d) (1.1.5)\n",
      "Requirement already satisfied: addict in /root/anaconda/envs/ai/lib/python3.8/site-packages (from open3d) (2.4.0)\n",
      "Requirement already satisfied: numpy in /root/anaconda/envs/ai/lib/python3.8/site-packages (from open3d) (1.18.5)\n",
      "Requirement already satisfied: notebook in /root/anaconda/envs/ai/lib/python3.8/site-packages (from open3d) (6.2.0)\n",
      "Requirement already satisfied: plyfile in /root/anaconda/envs/ai/lib/python3.8/site-packages (from open3d) (0.7.3)\n",
      "Requirement already satisfied: matplotlib in /root/anaconda/envs/ai/lib/python3.8/site-packages (from open3d) (3.3.2)\n",
      "Requirement already satisfied: sklearn in /root/anaconda/envs/ai/lib/python3.8/site-packages (from open3d) (0.0)\n",
      "Requirement already satisfied: pyyaml in /root/anaconda/envs/ai/lib/python3.8/site-packages (from open3d) (5.4.1)\n",
      "Requirement already satisfied: widgetsnbextension in /root/anaconda/envs/ai/lib/python3.8/site-packages (from open3d) (3.5.1)\n",
      "Requirement already satisfied: tqdm in /root/anaconda/envs/ai/lib/python3.8/site-packages (from open3d) (4.56.0)\n",
      "Requirement already satisfied: ipywidgets in /root/anaconda/envs/ai/lib/python3.8/site-packages (from open3d) (7.6.3)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /root/anaconda/envs/ai/lib/python3.8/site-packages (from ipywidgets->open3d) (5.0.5)\n",
      "Requirement already satisfied: nbformat>=4.2.0 in /root/anaconda/envs/ai/lib/python3.8/site-packages (from ipywidgets->open3d) (5.1.2)\n",
      "Requirement already satisfied: ipython>=4.0.0 in /root/anaconda/envs/ai/lib/python3.8/site-packages (from ipywidgets->open3d) (7.18.1)\n",
      "Requirement already satisfied: ipykernel>=4.5.1 in /root/anaconda/envs/ai/lib/python3.8/site-packages (from ipywidgets->open3d) (5.4.2)\n",
      "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /root/anaconda/envs/ai/lib/python3.8/site-packages (from ipywidgets->open3d) (1.0.0)\n",
      "Requirement already satisfied: jupyter-client in /root/anaconda/envs/ai/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets->open3d) (6.1.11)\n",
      "Requirement already satisfied: tornado>=4.2 in /root/anaconda/envs/ai/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets->open3d) (6.1)\n",
      "Requirement already satisfied: pickleshare in /root/anaconda/envs/ai/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets->open3d) (0.7.5)\n",
      "Requirement already satisfied: pygments in /root/anaconda/envs/ai/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets->open3d) (2.7.4)\n",
      "Requirement already satisfied: pexpect>4.3 in /root/anaconda/envs/ai/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets->open3d) (4.8.0)\n",
      "Requirement already satisfied: jedi>=0.10 in /root/anaconda/envs/ai/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets->open3d) (0.18.0)\n",
      "Requirement already satisfied: backcall in /root/anaconda/envs/ai/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets->open3d) (0.2.0)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /root/anaconda/envs/ai/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets->open3d) (3.0.14)\n",
      "Requirement already satisfied: setuptools>=18.5 in /root/anaconda/envs/ai/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets->open3d) (49.6.0.post20210108)\n",
      "Requirement already satisfied: decorator in /root/anaconda/envs/ai/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets->open3d) (4.4.2)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /root/anaconda/envs/ai/lib/python3.8/site-packages (from jedi>=0.10->ipython>=4.0.0->ipywidgets->open3d) (0.8.1)\n",
      "Requirement already satisfied: ipython-genutils in /root/anaconda/envs/ai/lib/python3.8/site-packages (from nbformat>=4.2.0->ipywidgets->open3d) (0.2.0)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /root/anaconda/envs/ai/lib/python3.8/site-packages (from nbformat>=4.2.0->ipywidgets->open3d) (3.2.0)\n",
      "Requirement already satisfied: jupyter-core in /root/anaconda/envs/ai/lib/python3.8/site-packages (from nbformat>=4.2.0->ipywidgets->open3d) (4.7.0)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /root/anaconda/envs/ai/lib/python3.8/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets->open3d) (0.17.3)\n",
      "Requirement already satisfied: six>=1.11.0 in /root/anaconda/envs/ai/lib/python3.8/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets->open3d) (1.15.0)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /root/anaconda/envs/ai/lib/python3.8/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets->open3d) (20.3.0)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /root/anaconda/envs/ai/lib/python3.8/site-packages (from pexpect>4.3->ipython>=4.0.0->ipywidgets->open3d) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /root/anaconda/envs/ai/lib/python3.8/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets->open3d) (0.2.5)\n",
      "Requirement already satisfied: pyzmq>=17 in /root/anaconda/envs/ai/lib/python3.8/site-packages (from notebook->open3d) (21.0.1)\n",
      "Requirement already satisfied: prometheus-client in /root/anaconda/envs/ai/lib/python3.8/site-packages (from notebook->open3d) (0.9.0)\n",
      "Requirement already satisfied: argon2-cffi in /root/anaconda/envs/ai/lib/python3.8/site-packages (from notebook->open3d) (20.1.0)\n",
      "Requirement already satisfied: Send2Trash>=1.5.0 in /root/anaconda/envs/ai/lib/python3.8/site-packages (from notebook->open3d) (1.5.0)\n",
      "Requirement already satisfied: terminado>=0.8.3 in /root/anaconda/envs/ai/lib/python3.8/site-packages (from notebook->open3d) (0.9.2)\n",
      "Requirement already satisfied: jinja2 in /root/anaconda/envs/ai/lib/python3.8/site-packages (from notebook->open3d) (2.11.2)\n",
      "Requirement already satisfied: nbconvert in /root/anaconda/envs/ai/lib/python3.8/site-packages (from notebook->open3d) (6.0.7)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /root/anaconda/envs/ai/lib/python3.8/site-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets->open3d) (2.8.1)\n",
      "Requirement already satisfied: cffi>=1.0.0 in /root/anaconda/envs/ai/lib/python3.8/site-packages (from argon2-cffi->notebook->open3d) (1.14.4)\n",
      "Requirement already satisfied: pycparser in /root/anaconda/envs/ai/lib/python3.8/site-packages (from cffi>=1.0.0->argon2-cffi->notebook->open3d) (2.20)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /root/anaconda/envs/ai/lib/python3.8/site-packages (from jinja2->notebook->open3d) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /root/anaconda/envs/ai/lib/python3.8/site-packages (from matplotlib->open3d) (0.10.0)\n",
      "Requirement already satisfied: certifi>=2020.06.20 in /root/anaconda/envs/ai/lib/python3.8/site-packages (from matplotlib->open3d) (2020.12.5)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /root/anaconda/envs/ai/lib/python3.8/site-packages (from matplotlib->open3d) (8.1.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /root/anaconda/envs/ai/lib/python3.8/site-packages (from matplotlib->open3d) (1.3.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /root/anaconda/envs/ai/lib/python3.8/site-packages (from matplotlib->open3d) (2.4.7)\n",
      "Requirement already satisfied: jupyterlab-pygments in /root/anaconda/envs/ai/lib/python3.8/site-packages (from nbconvert->notebook->open3d) (0.1.2)\n",
      "Requirement already satisfied: testpath in /root/anaconda/envs/ai/lib/python3.8/site-packages (from nbconvert->notebook->open3d) (0.4.4)\n",
      "Requirement already satisfied: bleach in /root/anaconda/envs/ai/lib/python3.8/site-packages (from nbconvert->notebook->open3d) (3.2.3)\n",
      "Requirement already satisfied: entrypoints>=0.2.2 in /root/anaconda/envs/ai/lib/python3.8/site-packages (from nbconvert->notebook->open3d) (0.3)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in /root/anaconda/envs/ai/lib/python3.8/site-packages (from nbconvert->notebook->open3d) (0.8.4)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /root/anaconda/envs/ai/lib/python3.8/site-packages (from nbconvert->notebook->open3d) (1.4.2)\n",
      "Requirement already satisfied: nbclient<0.6.0,>=0.5.0 in /root/anaconda/envs/ai/lib/python3.8/site-packages (from nbconvert->notebook->open3d) (0.5.1)\n",
      "Requirement already satisfied: defusedxml in /root/anaconda/envs/ai/lib/python3.8/site-packages (from nbconvert->notebook->open3d) (0.6.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: async-generator in /root/anaconda/envs/ai/lib/python3.8/site-packages (from nbclient<0.6.0,>=0.5.0->nbconvert->notebook->open3d) (1.10)\n",
      "Requirement already satisfied: nest-asyncio in /root/anaconda/envs/ai/lib/python3.8/site-packages (from nbclient<0.6.0,>=0.5.0->nbconvert->notebook->open3d) (1.4.3)\n",
      "Requirement already satisfied: webencodings in /root/anaconda/envs/ai/lib/python3.8/site-packages (from bleach->nbconvert->notebook->open3d) (0.5.1)\n",
      "Requirement already satisfied: packaging in /root/anaconda/envs/ai/lib/python3.8/site-packages (from bleach->nbconvert->notebook->open3d) (20.8)\n",
      "Requirement already satisfied: pytz>=2017.2 in /root/anaconda/envs/ai/lib/python3.8/site-packages (from pandas->open3d) (2019.3)\n",
      "Requirement already satisfied: scikit-learn in /root/anaconda/envs/ai/lib/python3.8/site-packages (from sklearn->open3d) (0.23.2)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /root/anaconda/envs/ai/lib/python3.8/site-packages (from scikit-learn->sklearn->open3d) (1.4.1)\n",
      "Requirement already satisfied: joblib>=0.11 in /root/anaconda/envs/ai/lib/python3.8/site-packages (from scikit-learn->sklearn->open3d) (1.0.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /root/anaconda/envs/ai/lib/python3.8/site-packages (from scikit-learn->sklearn->open3d) (2.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install open3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from random import randrange\n",
    "from IPython.display import clear_output\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "from torch.autograd import Variable\n",
    "from datasets import PartDataset\n",
    "#from pointnet import PointNetCls\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import open3d as o3\n",
    "#import download\n",
    "from open3d import JVisualizer\n",
    "if torch.cuda.is_available():\n",
    "    import torch.backends.cudnn as cudnn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset\n",
    "\n",
    "We are going to work with the ShapeNet Dataset.\n",
    "It's coming from Standford and will allow us to do both Classification and Segmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: cannot verify shapenet.cs.stanford.edu's certificate, issued by ‘CN=InCommon RSA Server CA,OU=InCommon,O=Internet2,L=Ann Arbor,ST=MI,C=US’:\n",
      "  Issued certificate has expired.\n",
      "2021-02-16 11:45:10 URL:https://shapenet.cs.stanford.edu/ericyi/shapenetcore_partanno_segmentation_benchmark_v0.zip [666265910/666265910] -> \"shapenetcore_partanno_segmentation_benchmark_v0.zip\" [1]\n",
      "Archive:  shapenetcore_partanno_segmentation_benchmark_v0.zip\n",
      "replace shapenetcore_partanno_segmentation_benchmark_v0/02954340/seg_img/e823673c1edd73fb97c426435543a860.png? [y]es, [n]o, [A]ll, [N]one, [r]ename: ^C\n"
     ]
    }
   ],
   "source": [
    "#Run this only if you don't already have the Dataset\n",
    "!wget -nv https://shapenet.cs.stanford.edu/ericyi/shapenetcore_partanno_segmentation_benchmark_v0.zip --no-check-certificate\n",
    "!unzip shapenetcore_partanno_segmentation_benchmark_v0.zip\n",
    "!rm shapenetcore_partanno_segmentation_benchmark_v0.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avoid an SSL Error\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General parameters\n",
    "NUM_POINTS = 10000\n",
    "DATA_FOLDER = DATA_FOLDER = './shapenetcore_partanno_segmentation_benchmark_v0'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n",
      "{'Chair': 0}\n",
      "3371\n",
      "torch.Size([2500, 3]) torch.FloatTensor torch.Size([2500]) torch.LongTensor\n",
      "{'Airplane': 0, 'Bag': 1, 'Cap': 2, 'Car': 3, 'Chair': 4, 'Earphone': 5, 'Guitar': 6, 'Knife': 7, 'Lamp': 8, 'Laptop': 9, 'Motorbike': 10, 'Mug': 11, 'Pistol': 12, 'Rocket': 13, 'Skateboard': 14, 'Table': 15}\n",
      "15990\n",
      "torch.Size([2500, 3]) torch.FloatTensor torch.Size([1]) torch.LongTensor\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import torch.utils.data as data\n",
    "from PIL import Image\n",
    "import os\n",
    "import os.path\n",
    "import errno\n",
    "import torch\n",
    "import json\n",
    "import codecs\n",
    "import numpy as np\n",
    "import progressbar\n",
    "import sys\n",
    "import torchvision.transforms as transforms\n",
    "import argparse\n",
    "import json\n",
    "import open3d\n",
    "\n",
    "\n",
    "class PartDataset(data.Dataset):\n",
    "    def __init__(self, root, npoints = 2500, classification = False, class_choice = None, train = True):\n",
    "        self.npoints = npoints\n",
    "        self.root = root\n",
    "        self.catfile = os.path.join(self.root, 'synsetoffset2category.txt')\n",
    "        self.cat = {}\n",
    "\n",
    "        self.classification = classification\n",
    "\n",
    "        with open(self.catfile, 'r') as f:\n",
    "            for line in f:\n",
    "                ls = line.strip().split()\n",
    "                self.cat[ls[0]] = ls[1]\n",
    "        #print(self.cat)\n",
    "        if not class_choice is  None:\n",
    "            self.cat = {k:v for k,v in self.cat.items() if k in class_choice}\n",
    "\n",
    "        self.meta = {}\n",
    "        for item in self.cat:\n",
    "            #print('category', item)\n",
    "            self.meta[item] = []\n",
    "            dir_point = os.path.join(self.root, self.cat[item], 'points')\n",
    "            dir_seg = os.path.join(self.root, self.cat[item], 'points_label')\n",
    "            #print(dir_point, dir_seg)\n",
    "            fns = sorted(os.listdir(dir_point))\n",
    "            if train:\n",
    "                fns = fns[:int(len(fns) * 0.9)]\n",
    "            else:\n",
    "                fns = fns[int(len(fns) * 0.9):]\n",
    "\n",
    "            #print(os.path.basename(fns))\n",
    "            for fn in fns:\n",
    "                token = (os.path.splitext(os.path.basename(fn))[0])\n",
    "                self.meta[item].append((os.path.join(dir_point, token + '.pts'), os.path.join(dir_seg, token + '.seg')))\n",
    "\n",
    "        self.datapath = []\n",
    "        for item in self.cat:\n",
    "            for fn in self.meta[item]:\n",
    "                self.datapath.append((item, fn[0], fn[1]))\n",
    "\n",
    "\n",
    "        self.classes = dict(zip(sorted(self.cat), range(len(self.cat))))\n",
    "        print(self.classes)\n",
    "        self.num_seg_classes = 0\n",
    "        if not self.classification:\n",
    "            for i in range(len(self.datapath)//50):\n",
    "                l = len(np.unique(np.loadtxt(self.datapath[i][-1]).astype(np.uint8)))\n",
    "                if l > self.num_seg_classes:\n",
    "                    self.num_seg_classes = l\n",
    "        #print(self.num_seg_classes)\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        fn = self.datapath[index]\n",
    "        cls = self.classes[self.datapath[index][0]]\n",
    "        point_set = np.asarray(\n",
    "            open3d.io.read_point_cloud(fn[1], format='xyz').points,\n",
    "            dtype=np.float32)\n",
    "        seg = np.loadtxt(fn[2]).astype(np.int64)\n",
    "        #print(point_set.shape, seg.shape)\n",
    "\n",
    "        choice = np.random.choice(len(seg), self.npoints, replace=True)\n",
    "        #resample\n",
    "        point_set = point_set[choice, :]\n",
    "        seg = seg[choice]\n",
    "        point_set = torch.from_numpy(point_set)\n",
    "        seg = torch.from_numpy(seg)\n",
    "        cls = torch.from_numpy(np.array([cls]).astype(np.int64))\n",
    "        if self.classification:\n",
    "            return point_set, cls\n",
    "        else:\n",
    "            return point_set, seg\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.datapath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Airplane': 0, 'Bag': 1, 'Cap': 2, 'Car': 3, 'Chair': 4, 'Earphone': 5, 'Guitar': 6, 'Knife': 7, 'Lamp': 8, 'Laptop': 9, 'Motorbike': 10, 'Mug': 11, 'Pistol': 12, 'Rocket': 13, 'Skateboard': 14, 'Table': 15}\n"
     ]
    }
   ],
   "source": [
    "# Create dataset object\n",
    "test_dataset_seg = PartDataset(\n",
    "    root=DATA_FOLDER,\n",
    "    train=False,\n",
    "    classification=False,\n",
    "    npoints=NUM_POINTS)\n",
    "\n",
    "# Problem ontology\n",
    "classes_dict = {'Airplane': 0, 'Bag': 1, 'Cap': 2, 'Car': 3, 'Chair': 4, \n",
    "                'Earphone': 5, 'Guitar': 6, 'Knife': 7, 'Lamp': 8, 'Laptop': 9,\n",
    "                'Motorbike': 10, 'Mug': 11, 'Pistol': 12, 'Rocket': 13, \n",
    "                'Skateboard': 14, 'Table': 15}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the Dataset with Open3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Airplane': 0, 'Bag': 1, 'Cap': 2, 'Car': 3, 'Chair': 4, 'Earphone': 5, 'Guitar': 6, 'Knife': 7, 'Lamp': 8, 'Laptop': 9, 'Motorbike': 10, 'Mug': 11, 'Pistol': 12, 'Rocket': 13, 'Skateboard': 14, 'Table': 15}\n",
      "15990\n",
      "torch.Size([2500, 3]) torch.FloatTensor torch.Size([2500]) torch.LongTensor\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nd = PartDataset(root = 'shapenetcore_partanno_segmentation_benchmark_v0', classification = True)\\nprint(len(d))\\nps, cls = d[0]\\nprint(ps.size(), ps.type(), cls.size(),cls.type())\\n\""
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = PartDataset(root = 'shapenetcore_partanno_segmentation_benchmark_v0', class_choice = ['Airplane'])\n",
    "print(len(d))\n",
    "import random\n",
    "ps, seg = random.choice(d)\n",
    "print(ps.size(), ps.type(), seg.size(),seg.type())\n",
    "\n",
    "'''\n",
    "d = PartDataset(root = 'shapenetcore_partanno_segmentation_benchmark_v0', classification = True)\n",
    "print(len(d))\n",
    "ps, cls = d[0]\n",
    "print(ps.size(), ps.type(), cls.size(),cls.type())\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple point cloud coloring mapping\n",
    "def read_pointnet_colors(seg_labels):\n",
    "    map_label_to_rgb = {\n",
    "        1: [0, 255, 0],\n",
    "        2: [0, 0, 255],\n",
    "        3: [255, 0, 0],\n",
    "        4: [255, 0, 255],  # purple\n",
    "        5: [0, 255, 255],  # cyan\n",
    "        6: [255, 255, 0],  # yellow\n",
    "    }\n",
    "    colors = np.array([map_label_to_rgb[label] for label in seg_labels])\n",
    "    return colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e36b03f527124a86857e8d6b8ac0dbea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "JVisualizer with 1 geometries"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_vis = JVisualizer()\n",
    "test_vis.clear()\n",
    "clear_output()\n",
    "test_cloud = o3.geometry.PointCloud()\n",
    "test_cloud.points = o3.utility.Vector3dVector(ps)\n",
    "test_cloud.colors = o3.utility.Vector3dVector(read_pointnet_colors(seg.numpy()))\n",
    "\n",
    "test_vis.add_geometry(test_cloud)\n",
    "test_vis.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3D Deep Learning Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stn torch.Size([32, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "class STN3d(nn.Module):\n",
    "    \"\"\"\n",
    "    T-Net Model. \n",
    "    STN stands for Spatial Transformer Network.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_points = 2500):\n",
    "        super(STN3d, self).__init__()\n",
    "        self.num_points = num_points\n",
    "        self.conv1 = torch.nn.Conv1d(3, 64, 1)\n",
    "        self.conv2 = torch.nn.Conv1d(64, 128, 1)\n",
    "        self.conv3 = torch.nn.Conv1d(128, 1024, 1)\n",
    "        self.mp1 = torch.nn.MaxPool1d(num_points)\n",
    "        self.fc1 = nn.Linear(1024, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, 9)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        self.bn2 = nn.BatchNorm1d(128)\n",
    "        self.bn3 = nn.BatchNorm1d(1024)\n",
    "        self.bn4 = nn.BatchNorm1d(512)\n",
    "        self.bn5 = nn.BatchNorm1d(256)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        batchsize = x.size()[0]\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        x = self.mp1(x)\n",
    "        x = x.view(-1, 1024)\n",
    "\n",
    "        x = F.relu(self.bn4(self.fc1(x)))\n",
    "        x = F.relu(self.bn5(self.fc2(x)))\n",
    "        x = self.fc3(x)\n",
    "\n",
    "        iden = Variable(torch.from_numpy(np.array([1,0,0,0,1,0,0,0,1]).astype(np.float32))).view(1,9).repeat(batchsize,1)\n",
    "        if x.is_cuda:\n",
    "            iden = iden.cuda()\n",
    "        x = x + iden\n",
    "        x = x.view(-1, 3, 3)\n",
    "        return x\n",
    "\n",
    "sim_data = Variable(torch.rand(32,3,2500))\n",
    "trans = STN3d()\n",
    "out = trans(sim_data)\n",
    "print('stn', out.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PointNetfeat(nn.Module):\n",
    "    \"\"\"\n",
    "    This is the T-Net for Feature Transform.\n",
    "    There is also MLP part 64,128,1024.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_points = 2500, global_feat = True):\n",
    "        super(PointNetfeat, self).__init__()\n",
    "        self.stn = STN3d(num_points = num_points)\n",
    "        self.conv1 = torch.nn.Conv1d(3, 64, 1)\n",
    "        self.conv2 = torch.nn.Conv1d(64, 128, 1)\n",
    "        self.conv3 = torch.nn.Conv1d(128, 1024, 1)\n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        self.bn2 = nn.BatchNorm1d(128)\n",
    "        self.bn3 = nn.BatchNorm1d(1024)\n",
    "        self.mp1 = torch.nn.MaxPool1d(num_points)\n",
    "        self.num_points = num_points\n",
    "        self.global_feat = global_feat\n",
    "        \n",
    "    def forward(self, x):\n",
    "        batchsize = x.size()[0]\n",
    "        trans = self.stn(x)\n",
    "        x = x.transpose(2,1)\n",
    "        x = torch.bmm(x, trans)\n",
    "        x = x.transpose(2,1)\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        pointfeat = x\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.bn3(self.conv3(x))\n",
    "        x = self.mp1(x)\n",
    "        x = x.view(-1, 1024)\n",
    "        if self.global_feat:\n",
    "            return x, trans\n",
    "        else:\n",
    "            x = x.view(-1, 1024, 1).repeat(1, 1, self.num_points)\n",
    "            return torch.cat([x, pointfeat], 1), trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global feat torch.Size([32, 1024])\n"
     ]
    }
   ],
   "source": [
    "pointfeat = PointNetfeat(global_feat=True)\n",
    "out, _ = pointfeat(sim_data)\n",
    "print('global feat', out.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PointNetCls(nn.Module):\n",
    "    \"\"\"\n",
    "    Network for Classification: 512, 256, K.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_points = 2500, k = 2):\n",
    "        super(PointNetCls, self).__init__()\n",
    "        self.num_points = num_points\n",
    "        self.feat = PointNetfeat(num_points, global_feat=True)\n",
    "        self.fc1 = nn.Linear(1024, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, k)\n",
    "        self.bn1 = nn.BatchNorm1d(512)\n",
    "        self.bn2 = nn.BatchNorm1d(256)\n",
    "        self.relu = nn.ReLU()\n",
    "    def forward(self, x):\n",
    "        x, trans = self.feat(x)\n",
    "        x = F.relu(self.bn1(self.fc1(x)))\n",
    "        x = F.relu(self.bn2(self.fc2(x)))\n",
    "        x = self.fc3(x)\n",
    "        return F.log_softmax(x, dim=-1), trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global feat torch.Size([32, 1024])\n",
      "point feat torch.Size([32, 1088, 2500])\n",
      "class torch.Size([32, 5])\n"
     ]
    }
   ],
   "source": [
    "pointfeat = PointNetfeat(global_feat=True)\n",
    "out, _ = pointfeat(sim_data)\n",
    "print('global feat', out.size())\n",
    "\n",
    "pointfeat = PointNetfeat(global_feat=False)\n",
    "out, _ = pointfeat(sim_data)\n",
    "print('point feat', out.size())\n",
    "\n",
    "cls = PointNetCls(k = 5)\n",
    "out, _ = cls(sim_data)\n",
    "print('class', out.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PointNetDenseCls(nn.Module):\n",
    "    \"\"\"\n",
    "    Network for Segmentation\n",
    "    \"\"\"\n",
    "    def __init__(self, num_points = 2500, k = 2):\n",
    "        super(PointNetDenseCls, self).__init__()\n",
    "        self.num_points = num_points\n",
    "        self.k = k\n",
    "        self.feat = PointNetfeat(num_points, global_feat=False)\n",
    "        self.conv1 = torch.nn.Conv1d(1088, 512, 1)\n",
    "        self.conv2 = torch.nn.Conv1d(512, 256, 1)\n",
    "        self.conv3 = torch.nn.Conv1d(256, 128, 1)\n",
    "        self.conv4 = torch.nn.Conv1d(128, self.k, 1)\n",
    "        self.bn1 = nn.BatchNorm1d(512)\n",
    "        self.bn2 = nn.BatchNorm1d(256)\n",
    "        self.bn3 = nn.BatchNorm1d(128)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batchsize = x.size()[0]\n",
    "        x, trans = self.feat(x)\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        x = self.conv4(x)\n",
    "        x = x.transpose(2,1).contiguous()\n",
    "        x = F.log_softmax(x.view(-1,self.k), dim=-1)\n",
    "        x = x.view(batchsize, self.num_points, self.k)\n",
    "        return x, trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seg torch.Size([32, 2500, 3])\n"
     ]
    }
   ],
   "source": [
    "seg = PointNetDenseCls(k = 3)\n",
    "out, _ = seg(sim_data)\n",
    "print('seg', out.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Model for classification and segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = PointNetCls(k = num_classes, num_points = opt.num_points)\n",
    "\n",
    "\n",
    "if opt.model != '':\n",
    "    classifier.load_state_dict(torch.load(opt.model))\n",
    "\n",
    "\n",
    "optimizer = optim.SGD(classifier.parameters(), lr=0.01, momentum=0.9)\n",
    "if torch.cuda.is_available():\n",
    "    classifier.cuda()\n",
    "\n",
    "num_batch = len(dataset)/opt.batchSize\n",
    "\n",
    "for epoch in range(opt.nepoch):\n",
    "    for i, data in enumerate(dataloader, 0):\n",
    "        points, target = data\n",
    "        points, target = Variable(points), Variable(target[:,0])\n",
    "        points = points.transpose(2,1)\n",
    "        if torch.cuda.is_available():\n",
    "            points, target = points.cuda(), target.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        classifier = classifier.train()\n",
    "        pred, _ = classifier(points)\n",
    "        loss = F.nll_loss(pred, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        pred_choice = pred.data.max(1)[1]\n",
    "        correct = pred_choice.eq(target.data).cpu().sum()\n",
    "        print('[%d: %d/%d] train loss: %f accuracy: %f' %(epoch, i, num_batch, loss.item(),correct.item() / float(opt.batchSize)))\n",
    "\n",
    "        if i % 10 == 0:\n",
    "            j, data = next(enumerate(testdataloader, 0))\n",
    "            points, target = data\n",
    "            points, target = Variable(points), Variable(target[:,0])\n",
    "            points = points.transpose(2,1)\n",
    "            if torch.cuda.is_available():\n",
    "                points, target = points.cuda(), target.cuda()\n",
    "            classifier = classifier.eval()\n",
    "            pred, _ = classifier(points)\n",
    "            loss = F.nll_loss(pred, target)\n",
    "            pred_choice = pred.data.max(1)[1]\n",
    "            correct = pred_choice.eq(target.data).cpu().sum()\n",
    "            print('[%d: %d/%d] %s loss: %f accuracy: %f' %(epoch, i, num_batch, blue('test'), loss.item(), correct.item()/float(opt.batchSize)))\n",
    "\n",
    "    torch.save(classifier.state_dict(), '%s/cls_model_%d.pth' % (opt.outf, epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PointNetCls(\n",
       "  (feat): PointNetfeat(\n",
       "    (stn): STN3d(\n",
       "      (conv1): Conv1d(3, 64, kernel_size=(1,), stride=(1,))\n",
       "      (conv2): Conv1d(64, 128, kernel_size=(1,), stride=(1,))\n",
       "      (conv3): Conv1d(128, 1024, kernel_size=(1,), stride=(1,))\n",
       "      (mp1): MaxPool1d(kernel_size=10000, stride=10000, padding=0, dilation=1, ceil_mode=False)\n",
       "      (fc1): Linear(in_features=1024, out_features=512, bias=True)\n",
       "      (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
       "      (fc3): Linear(in_features=256, out_features=9, bias=True)\n",
       "      (relu): ReLU()\n",
       "      (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn3): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn4): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (conv1): Conv1d(3, 64, kernel_size=(1,), stride=(1,))\n",
       "    (conv2): Conv1d(64, 128, kernel_size=(1,), stride=(1,))\n",
       "    (conv3): Conv1d(128, 1024, kernel_size=(1,), stride=(1,))\n",
       "    (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (bn3): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (mp1): MaxPool1d(kernel_size=10000, stride=10000, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (fc1): Linear(in_features=1024, out_features=512, bias=True)\n",
       "  (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
       "  (fc3): Linear(in_features=256, out_features=16, bias=True)\n",
       "  (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the classification network from pre-trained model\n",
    "classifier = PointNetCls(k=len(classes_dict.items()), num_points=NUM_POINTS)\n",
    "if torch.cuda.is_available():\n",
    "    classifier.cuda()\n",
    "    classifier.load_state_dict(torch.load(MODEL_PATH))\n",
    "else:\n",
    "    classifier.load_state_dict(torch.load(MODEL_PATH, map_location='cpu'))\n",
    "classifier.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6535c285f274987a3a9d091b6cc4b7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "JVisualizer with 1 geometries"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Three.js based visualizer\n",
    "visualizer = JVisualizer()\n",
    "\n",
    "# Basic inference and visualization loop\n",
    "MAX_SAMPLES = 15\n",
    "for samples in range(MAX_SAMPLES):\n",
    "    random_index = randrange(len(test_dataset_seg))\n",
    "    print('[Sample {} / {}]'.format(random_index, len(test_dataset_seg)))\n",
    "    \n",
    "    # clean visualization\n",
    "    visualizer.clear()\n",
    "    clear_output()\n",
    "\n",
    "    # get next sample\n",
    "    point_set, seg = test_dataset_seg.__getitem__(random_index)\n",
    "\n",
    "    # create cloud for visualization\n",
    "    cloud = o3.geometry.PointCloud()\n",
    "    cloud.points = o3.utility.Vector3dVector(point_set)\n",
    "    cloud.colors = o3.utility.Vector3dVector(read_pointnet_colors(seg.numpy()))\n",
    "\n",
    "    # perform inference in GPU\n",
    "    points = Variable(point_set.unsqueeze(0))\n",
    "    points = points.transpose(2, 1)\n",
    "    if torch.cuda.is_available():\n",
    "        points = points.cuda()\n",
    "    pred_logsoft, _ = classifier(points)\n",
    "\n",
    "    # move data back to cpu for visualization\n",
    "    pred_logsoft_cpu = pred_logsoft.data.cpu().numpy().squeeze()\n",
    "    pred_soft_cpu = np.exp(pred_logsoft_cpu)\n",
    "    pred_class = np.argmax(pred_soft_cpu)\n",
    "\n",
    "    # let's visualize the input sample\n",
    "    visualizer.add_geometry(cloud)\n",
    "    visualizer.show()\n",
    "    \n",
    "    # Visualize probabilities\n",
    "    plt.xticks(list(classes_dict.values()), list(classes_dict.keys()),rotation=90)\n",
    "    plt.xlabel('Classes')\n",
    "    plt.ylabel('Probabilities')\n",
    "    plt.plot(list(classes_dict.values()), pred_soft_cpu)\n",
    "    plt.show()\n",
    "\n",
    "    input('Your object is a [{}] with probability {:0.3}. Press enter to continue!'\n",
    "          .format(list(classes_dict.keys())[pred_class], pred_soft_cpu[pred_class]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
